{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_config(cfgfile):\n",
    "    f = open(cfgfile,'r')\n",
    "    lines = f.read().split('\\n')\n",
    "    lines = [line for line in lines if len(line)>0]\n",
    "    lines = [line for line in lines if line[0] != '#']\n",
    "    lines = [line.rstrip().lstrip() for line in lines]\n",
    "    blocks = []\n",
    "    block = {}\n",
    "    for line in lines:\n",
    "        if line[0] == '[':\n",
    "            if len(block) != 0:\n",
    "                blocks.append(block)\n",
    "                block = {}\n",
    "            block['type'] = line[1:-1]\n",
    "        else:\n",
    "            left = line.split('=')[0].rstrip() \n",
    "            right = line.split('=')[1].lstrip()\n",
    "            block[left] = right\n",
    "    blocks.append(block)\n",
    "                \n",
    "    return blocks    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfgfile = 'yolov3.cfg'\n",
    "blocks = parse_config(cfgfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "9\n",
      "8\n",
      "15\n",
      "10\n",
      "8\n",
      "14\n",
      "9\n",
      "10\n",
      "10\n",
      "12\n",
      "12\n",
      "7\n",
      "16\n",
      "14\n",
      "6\n",
      "0\n",
      "19\n",
      "12\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(len(lines[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658\n"
     ]
    }
   ],
   "source": [
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "9\n",
      "8\n",
      "15\n",
      "10\n",
      "8\n",
      "14\n",
      "9\n",
      "10\n",
      "10\n",
      "12\n",
      "12\n",
      "7\n",
      "16\n",
      "14\n",
      "6\n",
      "19\n",
      "12\n",
      "20\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(len(lines[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n"
     ]
    }
   ],
   "source": [
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[net]\n",
      "batch=16\n",
      "subdivisions=1\n",
      "width=416\n",
      "height=416\n",
      "channels=3\n",
      "momentum=0.9\n",
      "decay=0.0005\n",
      "angle=0\n",
      "saturation = 1.5\n",
      "exposure = 1.5\n",
      "hue=.1\n",
      "learning_rate=0.001\n",
      "burn_in=1000\n",
      "max_batches = 500200\n",
      "policy=steps\n",
      "steps=400000,450000\n",
      "scales=.1,.1\n",
      "[convolutional]\n",
      "batch_normalize=1\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "print(len(blocks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./long.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./index.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'net', 'batch': '16', 'subdivisions': '1', 'width': '416', 'height': '416', 'channels': '3', 'momentum': '0.9', 'decay': '0.0005', 'angle': '0', 'saturation': '1.5', 'exposure': '1.5', 'hue': '.1', 'learning_rate': '0.001', 'burn_in': '1000', 'max_batches': '500200', 'policy': 'steps', 'steps': '400000,450000', 'scales': '.1,.1'}\n"
     ]
    }
   ],
   "source": [
    "print(blocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n"
     ]
    }
   ],
   "source": [
    "print(blocks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '64', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n"
     ]
    }
   ],
   "source": [
    "print(blocks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n"
     ]
    }
   ],
   "source": [
    "print(blocks[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[net]\n",
    "#Testing\n",
    "#batch=1\n",
    "#subdivisions=1\n",
    "#Training\n",
    "batch=16\n",
    "subdivisions=1\n",
    "width=416\n",
    "height=416\n",
    "channels=3\n",
    "momentum=0.9\n",
    "decay=0.0005\n",
    "angle=0\n",
    "saturation = 1.5\n",
    "exposure = 1.5\n",
    "hue=.1\n",
    "\n",
    "learning_rate=0.001\n",
    "burn_in=1000\n",
    "max_batches = 500200\n",
    "policy=steps\n",
    "steps=400000,450000\n",
    "scales=.1,.1\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=32\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
    "conv层有75个\n",
    "batchnorm层有72个\n",
    "需要加以判断\n",
    "可以发现yolo层之前的卷积层不含皮归一化层\n",
    "\n",
    "\n",
    "另外：108层的构成是\n",
    "        net_info:      1\n",
    "        convlutional： 75\n",
    "        yolo：         3\n",
    "        shortcut:      23\n",
    "        route:         4\n",
    "        upsamble:      2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./yolov3.jpg\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmptyLayer(nn.Module):\n",
    "    #空层用于占位\n",
    "    def __init__(self):\n",
    "        super(EmptyLayer, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DetectionLayer(nn.Module):\n",
    "    #将检测抽象化为一个层\n",
    "    def __init__(self, anchors):\n",
    "        super(DetectionLayer, self).__init__()\n",
    "        self.anchors = anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[yolo]\n",
    "mask = 6,7,8\n",
    "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
    "classes=80\n",
    "num=9\n",
    "jitter=.3\n",
    "ignore_thresh = .7\n",
    "truth_thresh = 1\n",
    "random=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net(blocks):\n",
    "    \n",
    "    net_info = blocks[0]\n",
    "    prev_filters = 3\n",
    "    output_filters = []\n",
    "    net_list = nn.ModuleList()\n",
    "    \n",
    "    for index,layer in enumerate(blocks[1:]):\n",
    "        onelayer = nn.Sequential()\n",
    "        if layer['type'] == 'convolutional':\n",
    "            try:\n",
    "                batchnorm = int(layer['batch_normalize'])\n",
    "                bias = True\n",
    "            except:\n",
    "                batchnorm = 0\n",
    "            bias = False\n",
    "            out_channels = int(layer['filters'])\n",
    "            kernel_size = int(layer['size'])\n",
    "            stride = int(layer['stride'])\n",
    "            pad = int(layer['pad'])\n",
    "            activation = layer['activation']\n",
    "            conv = nn.Conv2d(in_channels = prev_filters,\n",
    "                             out_channels = out_channels,\n",
    "                             kernel_size = kernel_size,\n",
    "                             stride = stride,\n",
    "                             padding = pad,\n",
    "                             bias = bias)\n",
    "            onelayer.add_module(\"conv_{0}\".format(index), conv)\n",
    "            if batchnorm:\n",
    "                bn = nn.BatchNorm2d(out_channels)\n",
    "                onelayer.add_module(\"bn_{0}\".format(index),bn)\n",
    "            if activation == 'leaky':\n",
    "                activaten = nn.LeakyReLU(0.1)\n",
    "                onelayer.add_module(\"activate_{0}\".format(index),activaten)\n",
    "        \n",
    "        elif layer['type'] == 'shortcut':\n",
    "            shortcut = EmptyLayer()\n",
    "            onelayer.add_module(\"shortcut_{}\".format(index), shortcut)\n",
    "\n",
    "            \n",
    "        elif layer['type'] == 'route':\n",
    "            route = EmptyLayer()\n",
    "            two = layer['layers'].split(',')\n",
    "            try:\n",
    "                index1 = int(two[1])\n",
    "                index2 = int(two[0])\n",
    "                \n",
    "            except:\n",
    "                index1 = 0\n",
    "                index2 = int(two[0])\n",
    "            \n",
    "            if index1 == 0:\n",
    "                out_channels = output_filters[index + index2]\n",
    "            else:\n",
    "                if index1 < 0:\n",
    "                    out_channels = output_filters[index + index1] + output_filters[index2]\n",
    "                else:\n",
    "                    out_channels = output_filters[index + index2] + output_filters[index1]\n",
    "            onelayer.add_module(\"route_{0}\".format(index),route)    \n",
    "            \n",
    "        elif layer['type'] == 'upsamble':\n",
    "            stride = int(layer['stride'])\n",
    "            upsam = nn.Upsample(scale_factor = stride, mode = \"bilinear\")\n",
    "            onelayer.add_module(\"upsamble_{0}\".format(index),upsam)\n",
    "            \n",
    "        elif layer['type'] == 'yolo':\n",
    "            mask = layer['mask'].split(',')\n",
    "            mask = [int(i) for i in mask]\n",
    "            archors = layer['anchors'].split('  ')\n",
    "            archor = [archors[i] for i in mask]\n",
    "            archor = [(int(i.split(',')[0]),int(i.split(',')[1])) for i in archor]\n",
    "            yolo = DetectionLayer(archor)\n",
    "            onelayer.add_module(\"yolo_{0}\".format(index),yolo)\n",
    "            \n",
    "        net_list.append(onelayer)\n",
    "        prev_filters = out_channels\n",
    "        output_filters.append(out_channels)\n",
    "        \n",
    "    return net_list\n",
    "                    \n",
    "                    \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(116, 90), (156, 198), (373, 326)]\n",
      "[(30, 61), (62, 45), (59, 119)]\n",
      "[(10, 13), (16, 30), (33, 23)]\n"
     ]
    }
   ],
   "source": [
    "out = create_net(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 32\n",
      "1 64\n",
      "2 32\n",
      "3 64\n",
      "4 64\n",
      "5 128\n",
      "6 64\n",
      "7 128\n",
      "8 128\n",
      "9 64\n",
      "10 128\n",
      "11 128\n",
      "12 256\n",
      "13 128\n",
      "14 256\n",
      "15 256\n",
      "16 128\n",
      "17 256\n",
      "18 256\n",
      "19 128\n",
      "20 256\n",
      "21 256\n",
      "22 128\n",
      "23 256\n",
      "24 256\n",
      "25 128\n",
      "26 256\n",
      "27 256\n",
      "28 128\n",
      "29 256\n",
      "30 256\n",
      "31 128\n",
      "32 256\n",
      "33 256\n",
      "34 128\n",
      "35 256\n",
      "36 256\n",
      "37 512\n",
      "38 256\n",
      "39 512\n",
      "40 512\n",
      "41 256\n",
      "42 512\n",
      "43 512\n",
      "44 256\n",
      "45 512\n",
      "46 512\n",
      "47 256\n",
      "48 512\n",
      "49 512\n",
      "50 256\n",
      "51 512\n",
      "52 512\n",
      "53 256\n",
      "54 512\n",
      "55 512\n",
      "56 256\n",
      "57 512\n",
      "58 512\n",
      "59 256\n",
      "60 512\n",
      "61 512\n",
      "62 1024\n",
      "63 512\n",
      "64 1024\n",
      "65 1024\n",
      "66 512\n",
      "67 1024\n",
      "68 1024\n",
      "69 512\n",
      "70 1024\n",
      "71 1024\n",
      "72 512\n",
      "73 1024\n",
      "74 1024\n",
      "75 512\n",
      "76 1024\n",
      "77 512\n",
      "78 1024\n",
      "79 512\n",
      "80 1024\n",
      "81 255\n",
      "82 255\n",
      "83 512\n",
      "84 256\n",
      "85 256\n",
      "86 768\n",
      "87 256\n",
      "88 512\n",
      "89 256\n",
      "90 512\n",
      "91 256\n",
      "92 512\n",
      "93 255\n",
      "94 255\n",
      "95 256\n",
      "96 128\n",
      "97 128\n",
      "98 384\n",
      "99 128\n",
      "100 256\n",
      "101 128\n",
      "102 256\n",
      "103 128\n",
      "104 256\n",
      "105 255\n",
      "106 255\n"
     ]
    }
   ],
   "source": [
    "for index,i in enumerate(out):\n",
    "    print(index,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Sequential(\n",
       "    (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_0): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_1): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_3): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (shortcut_4): EmptyLayer()\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_5): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_6): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_7): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (8): Sequential(\n",
       "    (shortcut_8): EmptyLayer()\n",
       "  )\n",
       "  (9): Sequential(\n",
       "    (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_9): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (10): Sequential(\n",
       "    (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_10): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (11): Sequential(\n",
       "    (shortcut_11): EmptyLayer()\n",
       "  )\n",
       "  (12): Sequential(\n",
       "    (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_12): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (13): Sequential(\n",
       "    (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_13): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (14): Sequential(\n",
       "    (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_14): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (15): Sequential(\n",
       "    (shortcut_15): EmptyLayer()\n",
       "  )\n",
       "  (16): Sequential(\n",
       "    (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_16): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (17): Sequential(\n",
       "    (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_17): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (18): Sequential(\n",
       "    (shortcut_18): EmptyLayer()\n",
       "  )\n",
       "  (19): Sequential(\n",
       "    (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_19): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (20): Sequential(\n",
       "    (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_20): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (21): Sequential(\n",
       "    (shortcut_21): EmptyLayer()\n",
       "  )\n",
       "  (22): Sequential(\n",
       "    (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_22): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (23): Sequential(\n",
       "    (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_23): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (24): Sequential(\n",
       "    (shortcut_24): EmptyLayer()\n",
       "  )\n",
       "  (25): Sequential(\n",
       "    (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_25): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (26): Sequential(\n",
       "    (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_26): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (27): Sequential(\n",
       "    (shortcut_27): EmptyLayer()\n",
       "  )\n",
       "  (28): Sequential(\n",
       "    (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_28): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (29): Sequential(\n",
       "    (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_29): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (30): Sequential(\n",
       "    (shortcut_30): EmptyLayer()\n",
       "  )\n",
       "  (31): Sequential(\n",
       "    (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_31): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (32): Sequential(\n",
       "    (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_32): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (33): Sequential(\n",
       "    (shortcut_33): EmptyLayer()\n",
       "  )\n",
       "  (34): Sequential(\n",
       "    (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_34): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (35): Sequential(\n",
       "    (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_35): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (36): Sequential(\n",
       "    (shortcut_36): EmptyLayer()\n",
       "  )\n",
       "  (37): Sequential(\n",
       "    (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_37): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (38): Sequential(\n",
       "    (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_38): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (39): Sequential(\n",
       "    (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_39): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (40): Sequential(\n",
       "    (shortcut_40): EmptyLayer()\n",
       "  )\n",
       "  (41): Sequential(\n",
       "    (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_41): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (42): Sequential(\n",
       "    (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_42): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (43): Sequential(\n",
       "    (shortcut_43): EmptyLayer()\n",
       "  )\n",
       "  (44): Sequential(\n",
       "    (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_44): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (45): Sequential(\n",
       "    (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_45): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (46): Sequential(\n",
       "    (shortcut_46): EmptyLayer()\n",
       "  )\n",
       "  (47): Sequential(\n",
       "    (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_47): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (48): Sequential(\n",
       "    (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_48): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (49): Sequential(\n",
       "    (shortcut_49): EmptyLayer()\n",
       "  )\n",
       "  (50): Sequential(\n",
       "    (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_50): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (51): Sequential(\n",
       "    (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_51): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (52): Sequential(\n",
       "    (shortcut_52): EmptyLayer()\n",
       "  )\n",
       "  (53): Sequential(\n",
       "    (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_53): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (54): Sequential(\n",
       "    (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_54): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (55): Sequential(\n",
       "    (shortcut_55): EmptyLayer()\n",
       "  )\n",
       "  (56): Sequential(\n",
       "    (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_56): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (57): Sequential(\n",
       "    (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_57): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (58): Sequential(\n",
       "    (shortcut_58): EmptyLayer()\n",
       "  )\n",
       "  (59): Sequential(\n",
       "    (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_59): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (60): Sequential(\n",
       "    (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_60): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (61): Sequential(\n",
       "    (shortcut_61): EmptyLayer()\n",
       "  )\n",
       "  (62): Sequential(\n",
       "    (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_62): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (63): Sequential(\n",
       "    (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_63): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (64): Sequential(\n",
       "    (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_64): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (65): Sequential(\n",
       "    (shortcut_65): EmptyLayer()\n",
       "  )\n",
       "  (66): Sequential(\n",
       "    (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_66): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (67): Sequential(\n",
       "    (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_67): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (68): Sequential(\n",
       "    (shortcut_68): EmptyLayer()\n",
       "  )\n",
       "  (69): Sequential(\n",
       "    (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_69): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (70): Sequential(\n",
       "    (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_70): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (71): Sequential(\n",
       "    (shortcut_71): EmptyLayer()\n",
       "  )\n",
       "  (72): Sequential(\n",
       "    (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_72): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (73): Sequential(\n",
       "    (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_73): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (74): Sequential(\n",
       "    (shortcut_74): EmptyLayer()\n",
       "  )\n",
       "  (75): Sequential(\n",
       "    (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_75): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (76): Sequential(\n",
       "    (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_76): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (77): Sequential(\n",
       "    (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_77): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (78): Sequential(\n",
       "    (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_78): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (79): Sequential(\n",
       "    (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_79): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (80): Sequential(\n",
       "    (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_80): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (81): Sequential(\n",
       "    (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (82): Sequential(\n",
       "    (yolo_82): DetectionLayer()\n",
       "  )\n",
       "  (83): Sequential(\n",
       "    (route_83): EmptyLayer()\n",
       "  )\n",
       "  (84): Sequential(\n",
       "    (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_84): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (85): Sequential()\n",
       "  (86): Sequential(\n",
       "    (route_86): EmptyLayer()\n",
       "  )\n",
       "  (87): Sequential(\n",
       "    (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_87): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (88): Sequential(\n",
       "    (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_88): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (89): Sequential(\n",
       "    (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_89): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (90): Sequential(\n",
       "    (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_90): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (91): Sequential(\n",
       "    (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_91): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (92): Sequential(\n",
       "    (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_92): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (93): Sequential(\n",
       "    (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (94): Sequential(\n",
       "    (yolo_94): DetectionLayer()\n",
       "  )\n",
       "  (95): Sequential(\n",
       "    (route_95): EmptyLayer()\n",
       "  )\n",
       "  (96): Sequential(\n",
       "    (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_96): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (97): Sequential()\n",
       "  (98): Sequential(\n",
       "    (route_98): EmptyLayer()\n",
       "  )\n",
       "  (99): Sequential(\n",
       "    (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_99): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (100): Sequential(\n",
       "    (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_100): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (101): Sequential(\n",
       "    (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_101): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (102): Sequential(\n",
       "    (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_102): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (103): Sequential(\n",
       "    (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_103): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (104): Sequential(\n",
       "    (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activate_104): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (105): Sequential(\n",
       "    (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (106): Sequential(\n",
       "    (yolo_106): DetectionLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.MSELoss() \n",
    "nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class YOLOlayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, anchors):\n",
    "        super(YOLOlayer, self).__init__()\n",
    "        self.anchors = anchors\n",
    "        self.anchor_num = len(anchors)\n",
    "        self.img_dim = 416\n",
    "        self.classes = 80\n",
    "        self.box_attrs = self.classes + 5\n",
    "        self.ignore_thred = 0.5\n",
    "        self.lambda = 1\n",
    "        \n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        \n",
    "    def forward(self,x,target = None):\n",
    "        #共有三层yolo层 13*13 26*26 52*52 \n",
    "        #假定此处为16*255*13*13\n",
    "        batch_size = x.size(0)\n",
    "        fmap_size = x.size(2)\n",
    "        stride = self.img_dim / fmap_size\n",
    "        #类型占位\n",
    "        FloatTensor = torch.cuda.FloatTensor if x.is_cuda else torch.FloatTensor\n",
    "        LongTensor = torch.cuda.LongTensor if x.is_cuda else torch.LongTensor\n",
    "        #[16,255,13,13]-->[16,3,85,13,13]-->[16,3,13,13,85]\n",
    "        predict = x.view(batch_size,self.anchor_num,self.box_attrs,fmap_size.fmap_size).permute(0,1,3,4,2).contiguous()\n",
    "        \n",
    "        #yolo层对输入进行映射变化\n",
    "        x = torch.sigmoid(predic[..., 0])        #[16,3,13,13]  \n",
    "        y = torch.sigmoid(predic[..., 1])       \n",
    "        w = predic[..., 2]                         \n",
    "        h = predic[..., 3]                         \n",
    "        conf = torch.sigmoid(predic[..., 4])       \n",
    "        class_conf = torch.sigmoid(predict[..., 5:]) \n",
    "        \n",
    "        #13*13的网格\n",
    "        \n",
    "        grid_x = torch.linspace(0,fmap_size-1,fmap_size).repeat(fmap_size,1).repeat(self.anchor_num*batch_size,1,1).view(x.shape).type(FloatTensor)\n",
    "        grid_y = torch.linspace(0,fmap_size-1,fmap_size).repeat(fmap_size,1).t().repeat(self.anchor_num*batch_size,1,1).view(y.shape).type(FloatTensor)\n",
    "        anchors_scaled = [(anchor_x/stride,anchor_y/stride) for anchor_x,anchor_y in self.anchors]\n",
    "        \n",
    "        #取锚框坐标\n",
    "        anchor_x = FloatTensor(anchors_scaled).index_select(1,LongTensor([0]))#[3,1]\n",
    "        anchor_y = FloatTensor(anchors_scaled).index_select(1,LongTensor([1]))#[3,1]\n",
    "        #锚框转换到了 [16,3,13,13]\n",
    "        anchor_x = anchor_x.repeat(batch_size, 1).repeat(1, 1, fmap_size*fmap_size).view(w.shape)\n",
    "        anchor_y = anchor_y.repeat(batch_size, 1).repeat(1, 1, fmap_size*fmap_size).view(w.shape)\n",
    "        #存放预测结果的地方，尺寸为[16,3,13,13,4]\n",
    "        predict_boxes = FloatTensor(predic[..., :4].shape)\n",
    "        predict_boxes[...,0] = \n",
    "        predict_boxes[...,1] = \n",
    "        predict_boxes[...,2] =\n",
    "        predict_boxes[...,3] =\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "anch = [(0,1),(0,2),(0,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anch_y = FloatTensor(anch).index_select(1,LongTensor([1]))\n",
    "anch_y.reapeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "FloatTensor = torch.FloatTensor\n",
    "LongTensor = torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./box.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:yolotest]",
   "language": "python",
   "name": "conda-env-yolotest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
